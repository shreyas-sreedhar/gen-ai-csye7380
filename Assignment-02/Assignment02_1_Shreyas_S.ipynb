{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRON7D9HnrSB7fuwV4EqPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyas-sreedhar/gen-ai-csye7380/blob/main/Assignment-02/Assignment02_1_Shreyas_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSYE7380 - Assignment 02_1 - Shreyas Sreedhar"
      ],
      "metadata": {
        "id": "Kpu9jfjYRIpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Study the back-propagation algorithm. Implement a classifier for the loan data with Decision as the output attribute. Prepare the data as needed. Submit the notebook file."
      ],
      "metadata": {
        "id": "m0FVbozOKRzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagation is the algorithm used for training the neural network. Here's how it works:\n",
        "\n",
        "Forward Pass:\n",
        "The input data goes through the network, and an initial prediction is made.\n",
        "\n",
        "Loss Calculation:\n",
        "The network calculates how far its prediction is from the true target value using a loss function. We use binary_crossentropy for binary classification.\n",
        "\n",
        "Backpropagation:\n",
        "The network adjusts the weights of the neurons based on how much they contributed to the prediction error. This is done using gradient descent, which minimizes the loss function. The optimization process is powered by the Adam optimizer, which is an efficient variant of gradient descent.\n",
        "\n",
        "Epochs and Batches:\n",
        "Epochs: The number of times the entire dataset is passed through the neural network. In the code, we train for 50 epochs.\n",
        "\n",
        "Batch Size: During training, the data is broken into smaller batches of 16 records at a time. This allows the model to update weights more frequently and stabilize faster."
      ],
      "metadata": {
        "id": "ubeuRomWPsDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJYJdpp8NEI1",
        "outputId": "693c8b6d-8c36-4732-e8e6-15f1483706b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "9ndUOj-dNC7j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'https://raw.githubusercontent.com/shreyas-sreedhar/gen-ai-csye7380/main/Assignment-01/loan_csv.csv'\n",
        "loan_data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "inqqY5uOQF6C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_encoders = {}\n",
        "categorical_columns = ['Sex', 'Res_status', 'Telephone', 'Occupation', 'Job_status', 'Liab_ref', 'Acc_ref', 'Decision']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    loan_data[col] = label_encoders[col].fit_transform(loan_data[col])\n",
        "\n",
        "#target variable\n",
        "X = loan_data.drop(columns=['Decision'])\n",
        "y = loan_data['Decision']\n"
      ],
      "metadata": {
        "id": "ILTFflxPQNGa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#makingitnumerical\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['Age', 'Time_at_address', 'Time_employed', 'Time_bank', 'Home_Expn', 'Balance']\n",
        "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n"
      ],
      "metadata": {
        "id": "00Dd9SKQQTjt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),  # Input + first hidden layer\n",
        "    layers.Dense(8, activation='relu'),  # Second hidden layer\n",
        "    layers.Dense(1, activation='sigmoid')  # Output layer\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmYMM0MiQbfN",
        "outputId": "6c6a8af2-5bfa-4d07-b69c-d447ff888870"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has 3 layers:\n",
        "\n",
        "**Input Layer:** This takes in the 13 features of the data (like Age, Time_employed, etc.).\n",
        "\n",
        "**Hidden Layers:** We added two hidden layers with 16 and 8 neurons, respectively, using the ReLU (Rectified Linear Unit) activation function, which allows the network to capture complex, non-linear relationships between input data and the target label (Decision).\n",
        "\n",
        "**Output Layer**: Since this is a binary classification problem (accept/reject), we use one neuron with the Sigmoid activation function. This function outputs a value between 0 and 1, which represents the probability of the Decision being accept.\n"
      ],
      "metadata": {
        "id": "uUjGsbAaPfmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use keras to have\n",
        "Dense(16, activation='relu'): 16 neurons in the first hidden layer, using the ReLU function.\n",
        "\n",
        "Dense(8, activation='relu'): 8 neurons in the second hidden layer.\n",
        "\n",
        "Dense(1, activation='sigmoid'): Output layer with one neuron and sigmoid function for binary classification."
      ],
      "metadata": {
        "id": "LLzqBo3QQ78A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=150, batch_size=16, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jco1vXzDNTnV",
        "outputId": "ef91b382-1ca1-4024-a18c-4bcfde45e35f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4904 - loss: 0.7645 - val_accuracy: 0.4348 - val_loss: 0.7432\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4722 - loss: 0.7513 - val_accuracy: 0.5217 - val_loss: 0.6764\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5528 - loss: 0.6829 - val_accuracy: 0.5942 - val_loss: 0.6446\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6377 - loss: 0.6414 - val_accuracy: 0.6667 - val_loss: 0.6255\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6886 - loss: 0.6182 - val_accuracy: 0.7246 - val_loss: 0.6108\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.6040 - val_accuracy: 0.7536 - val_loss: 0.5989\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 0.5671 - val_accuracy: 0.7681 - val_loss: 0.5875\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.5448 - val_accuracy: 0.7391 - val_loss: 0.5772\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.5618 - val_accuracy: 0.7391 - val_loss: 0.5719\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.5282 - val_accuracy: 0.7536 - val_loss: 0.5638\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.5386 - val_accuracy: 0.7536 - val_loss: 0.5559\n",
            "Epoch 12/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7686 - loss: 0.5439 - val_accuracy: 0.7536 - val_loss: 0.5504\n",
            "Epoch 13/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.5150 - val_accuracy: 0.7536 - val_loss: 0.5394\n",
            "Epoch 14/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.4929 - val_accuracy: 0.7536 - val_loss: 0.5334\n",
            "Epoch 15/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.5195 - val_accuracy: 0.7391 - val_loss: 0.5295\n",
            "Epoch 16/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8011 - loss: 0.4889 - val_accuracy: 0.7391 - val_loss: 0.5229\n",
            "Epoch 17/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.4855 - val_accuracy: 0.7391 - val_loss: 0.5180\n",
            "Epoch 18/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8328 - loss: 0.4641 - val_accuracy: 0.7391 - val_loss: 0.5107\n",
            "Epoch 19/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.4769 - val_accuracy: 0.7391 - val_loss: 0.5086\n",
            "Epoch 20/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8244 - loss: 0.4374 - val_accuracy: 0.7391 - val_loss: 0.5025\n",
            "Epoch 21/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8464 - loss: 0.4250 - val_accuracy: 0.7536 - val_loss: 0.4938\n",
            "Epoch 22/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.4534 - val_accuracy: 0.7536 - val_loss: 0.4941\n",
            "Epoch 23/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.4283 - val_accuracy: 0.7536 - val_loss: 0.4860\n",
            "Epoch 24/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8125 - loss: 0.4693 - val_accuracy: 0.7536 - val_loss: 0.4878\n",
            "Epoch 25/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.4443 - val_accuracy: 0.7536 - val_loss: 0.4870\n",
            "Epoch 26/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8263 - loss: 0.4459 - val_accuracy: 0.7536 - val_loss: 0.4836\n",
            "Epoch 27/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.4342 - val_accuracy: 0.7536 - val_loss: 0.4865\n",
            "Epoch 28/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 0.4415 - val_accuracy: 0.7536 - val_loss: 0.4899\n",
            "Epoch 29/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.4247 - val_accuracy: 0.7826 - val_loss: 0.4701\n",
            "Epoch 30/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8548 - loss: 0.4133 - val_accuracy: 0.7826 - val_loss: 0.4634\n",
            "Epoch 31/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.4159 - val_accuracy: 0.7826 - val_loss: 0.4656\n",
            "Epoch 32/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.4458 - val_accuracy: 0.7536 - val_loss: 0.4760\n",
            "Epoch 33/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8266 - loss: 0.4222 - val_accuracy: 0.7536 - val_loss: 0.4820\n",
            "Epoch 34/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.4114 - val_accuracy: 0.7536 - val_loss: 0.4792\n",
            "Epoch 35/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.4357 - val_accuracy: 0.7826 - val_loss: 0.4662\n",
            "Epoch 36/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8502 - loss: 0.4282 - val_accuracy: 0.7681 - val_loss: 0.4849\n",
            "Epoch 37/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.4399 - val_accuracy: 0.7826 - val_loss: 0.4645\n",
            "Epoch 38/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.3934 - val_accuracy: 0.7826 - val_loss: 0.4655\n",
            "Epoch 39/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8573 - loss: 0.4205 - val_accuracy: 0.7681 - val_loss: 0.4705\n",
            "Epoch 40/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.3358 - val_accuracy: 0.7826 - val_loss: 0.4611\n",
            "Epoch 41/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.4665 - val_accuracy: 0.7826 - val_loss: 0.4677\n",
            "Epoch 42/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8169 - loss: 0.4096 - val_accuracy: 0.7826 - val_loss: 0.4670\n",
            "Epoch 43/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 0.3872 - val_accuracy: 0.7826 - val_loss: 0.4686\n",
            "Epoch 44/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.3397 - val_accuracy: 0.7826 - val_loss: 0.4661\n",
            "Epoch 45/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.3729 - val_accuracy: 0.7826 - val_loss: 0.4710\n",
            "Epoch 46/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.3266 - val_accuracy: 0.7971 - val_loss: 0.4740\n",
            "Epoch 47/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3850 - val_accuracy: 0.7971 - val_loss: 0.4730\n",
            "Epoch 48/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3800 - val_accuracy: 0.7971 - val_loss: 0.4659\n",
            "Epoch 49/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.3724 - val_accuracy: 0.7971 - val_loss: 0.4584\n",
            "Epoch 50/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8598 - loss: 0.3796 - val_accuracy: 0.7971 - val_loss: 0.4663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"The Test Loss: {test_loss}\")\n",
        "print(f\"The Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSbD4YVoQhV4",
        "outputId": "3cd4e7bf-aa12-481c-9de9-06ce5fb27c9a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7140 - loss: 0.5685 \n",
            "The Test Loss: 0.5687097907066345\n",
            "The Test Accuracy: 0.7093023061752319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural network correctly predicted whether a loan would be accepted or rejected in 70% of the test cases, indicating that it has learned meaningful patterns in the data"
      ],
      "metadata": {
        "id": "3C3QmP4KP-pX"
      }
    }
  ]
}